## 一、随机变量特征数（一）
### 数学期望

$$E[g(X)] = \begin{cases} \sum_i g(x_i)p(x_i), & \text{离散} \\ \int^{+\infty}_{-\infty} g(x)p(x), & \text{连续} \end{cases}$$
1. $E(c) = c$
2. $E(aX) = aE(X)$
3. $E(g_1(X) \pm g_2(X)) = E(g_1(X)) \pm E(g_2(X))$
### 方差

$$\begin{matrix} V\!ar(X) = E(X - E(X))^2 = E(X^2) - (E(X))^2 \\ \sigma(X) = \sqrt{V\!ar(X)} \end{matrix}$$
1. $V\!ar(c) = 0$
2. $V\!ar(aX + b) = a^2V\!ar(X)$
### 切比雪夫不等式

设随机变量 $X$ 的期望和方差存在，对任意常数 $\varepsilon > 0$ 有
$$P(|X - E(X)| \geqslant \varepsilon) \leqslant \frac{V\!ar(X)}{\varepsilon^2}$$

## 二、离散分布
### 二项分布

$X \sim b(n,p)$ 记 $X$ 为 $n$ 重伯努利试验中事件 $A$ 发生的次数，$p$ 为每次试验中 $A$ 发生的概率
$$P(X = k) = \mathrm{C}_n^kp^k(1 - p)^{n - k} \text{,\quad} k = 0,1,\cdots,n$$
$X \sim b(1,p)$ 在 $n$ 重伯努利试验中，当 $n = 1$ 时，称 **两点分布**
$$P(X = x) = p^x(1 - p)^{1 - x} \text{,\quad} x = 0,1$$
### 几何分布

$X \sim Ge(p)$ 记 $X$ 为 $n$ 重伯努利试验中事件 $A$ 首次发生的次数，$p$ 为每次试验中 $A$ 发生的概率
$$P(X = k) = p(1 - p)^{k - 1} \text{,\quad} k = 1,2,\cdots$$
*几何分布的无记忆性* 设 $X \sim Ge(p)$，对任意正整数 $m$ 和 $n$，有
$$P(X > m + n | X > n) = P(X > n)$$
### 负二项分布

$X \sim Nb(r, p)$ 记 $X$ 为伯努利试验中事件 $A$ 第 $r$ 次发生的次数，$p$ 为每次试验中 $A$ 发生的概率
$$P(X = k) = \mathrm{C}_{k - 1}^{r - 1}p^r(1 - p)^{k - r} \text{,\quad} k = r,r+1,\cdots$$
### 超几何分布

$X \sim h(n,N,M)$ 从一个有限总体 $N$ 中进行 $n$ 次不放回抽样，$M$ 为其中目标个体总量 
$$\begin{matrix} P(X = k) = \frac{\tbinom{M}{k}\tbinom{N - M}{n - k}}{\tbinom{N}{n}} \\ k = 0,1,\cdots,r, r=\min(M,n), M \leqslant N, n \leqslant N \end{matrix}$$
当 $n \ll N$ 时，每次抽取后 $M/N = p$ 的改变甚微，可近似的看为放回抽样
$$\frac{\tbinom{M}{k}\tbinom{N - M}{n - k}}{\tbinom{N}{n}} \cong \mathrm{C}_n^kp^k(1 - p)^{n - k} \text{, \quad} p = \frac{M}{N}$$
### 泊松分布

$X \sim P(\lambda)$ 
$$P(X = k) = \frac{\lambda^k}{k!}e^{-\lambda} \text{,\quad} k = 1,2,\cdots$$
*泊松定理* 在 $n$ 重伯努利试验中，当 $n \to +\infty$ 时，有 $np_n \to \lambda$，则
$$\mathrm{C}_n^kp_n^k(1 - p_n)^{n - k} = \frac{\lambda^k}{k!}e^{-\lambda}$$

$$
\begin{aligned} \hline
&&& E(X) && E(X^2) && V\!ar(X) \\ \hline \\
& X \sim b(n,p) && np && n(n - 1)p^2 + np && np(1-p) \\  \\
& X \sim Ge(p) && \frac{1}{p} && \frac{2(1 - p)}{p^2} + \frac{1}{p} && \frac{1 - p}{p^2} \\ \\
& X \sim h(n,N,M) && n\frac{M}{N} && n(n - 1)\frac{M(M - 1)}{N(N - 1)} + n\frac{M}{N} && \frac{nM(N - M)(N - n)}{N^2(N - 1)} \\ \\
& X \sim P(\lambda) && \lambda && \lambda^2 + \lambda && \lambda \\ \\ \hline
\end{aligned}
$$

## 三、连续分布

### 均匀分布 $X \sim U(a, b)$

$$p(x) = \begin{cases} 
\frac{1}{b - a}, & a < x < b \\
0, & \text{其他}
\end{cases}$$
$$F(x) = \begin{cases}
0, & x < a \\
\frac{x - a}{b - a}, & a \leqslant x < b \\
1, & x \geqslant b
\end{cases}$$
### 指数分布 $X \sim Exp(\lambda)$

$$p(x) = \begin{cases} 
\lambda\mathrm{e}^{-\lambda x}, & x \geqslant 0 \\
0, & x < 0
\end{cases}$$
$$F(x) = \begin{cases} 
1 - \mathrm{e}^{-\lambda x}, & x \geqslant 0 \\
0, & x < 0
\end{cases}$$
*指数分布的无记忆性* 设 $X \sim Exp(\lambda)$，对任意正数 $s$ 和 $t$，有
$$P(X > s + t | X > s) = P(X > t)$$
### 正态分布 $X \sim N(\mu,\sigma^2)$

$$p(x) = \frac{1}{\sqrt{2\pi}\sigma}\mathrm{e}^{-\frac{(x - \mu)^2}{2\sigma}} \text{, \quad} -\infty < x < +\infty$$
$$F(x) = \frac{1}{\sqrt{2\pi}\sigma}\int^{x}_{-\infty}\mathrm{e}^{-\frac{(t - \mu)^2}{2\sigma}}\mathrm{d}t \text{, \quad} -\infty < x < +\infty$$
其中 $\mu$ 为位置参数，$\sigma$ 为尺度参数

- $\mu$ 决定了曲线对称轴的位值 $x = \mu$
- $\sigma$ 愈小，曲线高而瘦，$\sigma$ 愈大，曲线矮而胖

当 $\mu = 0, \sigma = 1$ 时称 **标准正态分布** $N(0,1)$
$$\varphi(u) = \frac{1}{\sqrt{2\pi}}\mathrm{e}^{-\frac{u^2}{2}} \text{, \quad} -\infty < u < +\infty$$
$$\Phi(u) = \frac{1}{\sqrt{2\pi}}\int^{u}_{-\infty}\mathrm{e}^{-\frac{t^2}{2}}\mathrm{d}t \text{, \quad} -\infty < u < +\infty$$
1. $\Phi(-u) = 1 - \Phi(u)$
2. $P(|U| < c) = \Phi(c) - \Phi(-c) = 2\Phi(c) - 1$

*正态分布标准化* 若 $X \sim N(\mu,\sigma)$，则 $(X - \mu)/\sigma \sim N(0,1)$
称 $X^* = (X - \mu)/\sigma$ 为 $X$ 的 **标准化随机变量**
### 伽马分布 $X \sim Ga(\alpha,\lambda)$

$$\begin{matrix} \Gamma(\alpha) = \int^{+\infty}_{0} x^{\alpha - 1}e^{-x} \mathrm{d}x \end{matrix} \text{, \quad} \alpha > 0$$
对于 **伽马函数** 有

1. $\Gamma(1) = 1 \text{, } \Gamma(1/2) = \sqrt{\pi}$
2. $\Gamma(\alpha + 1) = \alpha\Gamma(\alpha)$，当 $n$ 为自然数时，有 $\Gamma(n + 1) = n\Gamma(n) = n!$

$$p(x) = \begin{cases} 
\frac{\lambda^\alpha}{\Gamma(\alpha)}x^{\alpha - 1}\mathrm{e}^{-\lambda x}, & x \geqslant 0 \\
0, & x < 0
\end{cases} \text{, \quad} \alpha > 0 \text{, \quad} \lambda > 0$$
其中 $\alpha$ 为形状参数，$\lambda$ 为尺度参数

- $0 < \alpha < 1$ 时，$p(x)$ 是严格下降函数，在 $x = 0$ 处有奇异点
- $\alpha = 1$ 时，$p(x)$ 是严格下降函数，在 $x = 0$ 处 $p(0) = \lambda$
- $1 < \alpha \leqslant 2$ 时，$p(x)$ 是单峰函数（先上凸、再下凸），在 $x = \frac{\alpha - 1}{\lambda}$ 处有极大值点
- $\alpha > 2$ 时，$p(x)$ 是单峰函数（先下凸、再上凸、再下凸），在 $x = \frac{\alpha - 1}{\lambda}$ 处有极大值点
	注：$\alpha$ 越大，越趋近于正态分布

当 $\alpha = 1$ 时，是指数分布
$$Ga(1,\lambda) = Exp(\lambda)$$
当 $\alpha = n/2, \lambda = 1/2$ 时，是自由度为 $n$ 的 **$\chi^2$分布**
$$Ga(\frac{n}{2},\frac{1}{2}) = \chi^2(n)$$
### 贝塔分布 $X \sim Be(a,b)$

$$\begin{matrix} \mathrm{B}(a,b) = \int^{1}_{0} x^{a - 1}(1 - x)^{b - 1} \mathrm{d}x \end{matrix} \text{, \quad} a > 0 \text{, \quad} b > 0$$
对于 **贝塔函数** 有

1. $\mathrm{B}(a,b) = \mathrm{B}(b,a)$
2. $\mathrm{B}(a,b) = \frac{\Gamma(a)\Gamma(b)}{\Gamma(a + b)}$

$$p(x) = \begin{cases} 
\mathrm{B}(a,b)x^{\alpha - 1}(1 - x)^{b - 1}, & 0 < x < 1 \\
0, & \text{其他}
\end{cases} \text{, \quad} a > 0 \text{, \quad} b > 0$$
其中 $a$ 和 $b$ 为形状参数

- $a < 1, b < 1$ 时，$p(x)$ 是下凸的单峰函数
- $a < 1, b \geqslant 1$ 时，$p(x)$ 是下凸的单调减函数
- $a = 1, b = 1$ 时，$p(x) = 1, x \in (0,1)$
- $a \geqslant 1, b < 1$ 时，$p(x)$ 是下凸的单调增函数
- $a > 1, b > 1$ 时，$p(x)$ 是上凸的单峰函数

$a = 1, b = 1$ 时，是 $(0,1)$ 上的均匀分布
$$Be(1,1) = U(0,1)$$

$$\begin{aligned} \hline
&&& E(X) && E(X^2) && V\!ar(X) \\ \hline \\
& X \sim U(a,b) && \frac{a + b}{2} && \frac{a^2 + ab + b^2}{3} && \frac{(b - a)^2}{12} \\ \\
& X \sim Exp(\lambda) && \frac{1}{\lambda} && \frac{2}{\lambda^2} && \frac{1}{\lambda^2} \\ \\
& X \sim N(\mu,\sigma) && \mu && \mu^2 + \sigma^2 && \sigma^2 \\ \\
& X \sim Ga(\alpha,\lambda) && \frac{\alpha}{\lambda} && \frac{\alpha(\alpha + 1)}{\lambda^2} && \frac{\alpha}{\lambda^2} \\ \\ 
& X \sim \mathrm{B}(a,b) && \frac{a}{a + b} && \frac{a(a + 1)}{(a + b)(a + b + 1)} && \frac{ab}{(a + b)^2(a + b + 1)} \\ \\ \hline
\end{aligned}$$

## 四、随机变量的特征数（二）
### $k$ 阶矩

**$k$ 阶原点矩**
$$\mu_k = E(X^k)$$
**$k$ 阶中心矩**
$$v_k = E(X - E(X))^k = \sum^{k}_{i = 0} \tbinom{k}{i}\mu_i(-\mu_1)^{k - i}$$
一阶原点矩就是数学期望，二阶中心矩就是方差
### 变异系数

$$C_v(X) = \frac{\sigma(X)}{E(X)}$$
### 分位数

$$\begin{aligned} F(x_p) & = \int^{x_p}_{-\infty}p(x) \mathrm{d}x = p \\ 1 - F(x'_p) & = \int^{+\infty}_{x'_p}p(x) \mathrm{d}x = p \end{aligned} \quad p \in (0,1)$$
分位数 $x_p$ 把密度函数下的面积分为两块，左侧面积恰好为 $p$，称 **下侧 $p$ 分位数**；
同理 $x'_p$ 称 **上侧 $p$ 分位数**。
$p = 0.5$ 时，分位数 $x_{0.5}$ 称 **中位数**
$$F(x_{0.5}) = \int^{x_{0.5}}_{-\infty}p(x) \mathrm{d}x = 0.5$$
### 偏度系数

$$\beta_1 = \frac{v_3}{v^{3/2}_2}$$
- 当 $\beta_1 < 0$ 时，称负偏或左偏
- 当 $\beta_1 = 0$ 时，分布关于 $E(X)$ 对称
- 当 $\beta_1 > 0$ 时，称正偏或右偏
### 峰度系数

$$\beta_2 = \frac{v_4}{v^{2}_2} - 3$$
- 当 $\beta_1 < 0$ 时，标准化后分布形状比正态分布更平坦，称 **低峰度**
- 当 $\beta_1 = 0$ 时，标准化后分布形状与正态分布相当
- 当 $\beta_1 > 0$ 时，标准化后分布形状比正态分布更尖峭，称 **高峰度**